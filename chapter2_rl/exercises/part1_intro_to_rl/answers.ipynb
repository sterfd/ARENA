{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reinforcement Learning - Intro to RL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Armed Bandit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import Optional, Union, List, Tuple\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import einops\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "import gym.envs.registration\n",
    "import gym.spaces\n",
    "\n",
    "Arr = np.ndarray\n",
    "max_episode_steps = 1000\n",
    "N_RUNS = 200\n",
    "\n",
    "# Make sure exercises are in the path\n",
    "chapter = \"chapter2_rl\"\n",
    "exercises_dir = Path(f\"{os.getcwd().split(chapter)[0]}/{chapter}/exercises\").resolve()\n",
    "section_dir = (exercises_dir / \"part1_intro_to_rl\").resolve()\n",
    "if str(exercises_dir) not in sys.path: sys.path.append(str(exercises_dir))\n",
    "\n",
    "import part1_intro_to_rl.utils as utils\n",
    "import part1_intro_to_rl.tests as tests\n",
    "from plotly_utils import imshow\n",
    "\n",
    "MAIN = __name__ == \"__main__\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to OpenAI Gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ObsType = int\n",
    "ActType = int\n",
    "\n",
    "class MultiArmedBandit(gym.Env):\n",
    "    '''\n",
    "    A class representing a multi-armed bandit environment, based on OpenAI Gym's Env class.\n",
    "\n",
    "    Attributes:\n",
    "        action_space (gym.spaces.Discrete): The space of possible actions, representing the arms of the bandit.\n",
    "        observation_space (gym.spaces.Discrete): The space of possible observations.\n",
    "        num_arms (int): The number of arms in the bandit.\n",
    "        stationary (bool): Indicates whether the reward distribution (i.e. the arm_reward_means) is stationary or not.\n",
    "        arm_reward_means (np.ndarray): The mean rewards for each arm.\n",
    "    '''\n",
    "    action_space: gym.spaces.Discrete\n",
    "    observation_space: gym.spaces.Discrete\n",
    "    num_arms: int\n",
    "    stationary: bool\n",
    "    arm_reward_means: np.ndarray\n",
    "\n",
    "    def __init__(self, num_arms=10, stationary=True):\n",
    "        '''\n",
    "        Initializes the MultiArmedBandit environment.\n",
    "\n",
    "        Args:\n",
    "            num_arms (int): The number of arms for the bandit. Defaults to 10.\n",
    "            stationary (bool): Whether the bandit has a stationary reward distribution. Defaults to True.\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.num_arms = num_arms\n",
    "        self.stationary = stationary\n",
    "        self.observation_space = gym.spaces.Discrete(1)\n",
    "        self.action_space = gym.spaces.Discrete(num_arms)\n",
    "        self.reset()\n",
    "\n",
    "    def step(self, arm: ActType) -> Tuple[ObsType, float, bool, dict]:\n",
    "        '''\n",
    "        Takes an action by choosing an arm and returns the result of the action.\n",
    "\n",
    "        Args:\n",
    "            arm (ActType): The selected arm to pull in the bandit.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[ObsType, float, bool, dict]: A tuple containing the observation, reward, done flag, and additional info.\n",
    "        '''\n",
    "        assert self.action_space.contains(arm)\n",
    "        if not self.stationary:\n",
    "            q_drift = self.np_random.normal(loc=0.0, scale=0.01, size=self.num_arms)\n",
    "            self.arm_reward_means += q_drift\n",
    "            self.best_arm = int(np.argmax(self.arm_reward_means))\n",
    "        reward = self.np_random.normal(loc=self.arm_reward_means[arm], scale=1.0)\n",
    "        obs = 0\n",
    "        done = False\n",
    "        info = dict(best_arm=self.best_arm)\n",
    "        return (obs, reward, done, info)\n",
    "\n",
    "    def reset(self, seed: Optional[int]=None, options=None) -> ObsType:\n",
    "        '''\n",
    "        Resets the environment to its initial state.\n",
    "\n",
    "        Args:\n",
    "            seed (Optional[int]): The seed for random number generation. Defaults to None.\n",
    "            return_info (bool): If True, return additional info. Defaults to False.\n",
    "            options (dict): Additional options for environment reset. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            ObsType: The initial observation.\n",
    "        '''\n",
    "        super().reset(seed=seed)\n",
    "        if self.stationary:\n",
    "            self.arm_reward_means = self.np_random.normal(loc=0.0, scale=1.0, size=self.num_arms)\n",
    "        else:\n",
    "            self.arm_reward_means = np.zeros(shape=[self.num_arms])\n",
    "        self.best_arm = int(np.argmax(self.arm_reward_means))\n",
    "        return 0\n",
    "\n",
    "    def render(self, mode=\"human\"):\n",
    "        '''\n",
    "        Renders the state of the environment, in the form of a violin plot.\n",
    "        '''\n",
    "        assert mode == \"human\", f\"Mode {mode} not supported!\"\n",
    "        bandit_samples = []\n",
    "        for arm in range(self.action_space.n):\n",
    "            bandit_samples += [np.random.normal(loc=self.arm_reward_means[arm], scale=1.0, size=1000)]\n",
    "        plt.violinplot(bandit_samples, showmeans=True)\n",
    "        plt.xlabel(\"Bandit Arm\")\n",
    "        plt.ylabel(\"Reward Distribution\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our env inside its wrappers looks like: <TimeLimit<OrderEnforcing<MultiArmedBandit<ArmedBanditTestbed-v0>>>>\n"
     ]
    }
   ],
   "source": [
    "gym.envs.registration.register(\n",
    "    id=\"ArmedBanditTestbed-v0\",\n",
    "    entry_point=MultiArmedBandit,\n",
    "    max_episode_steps=max_episode_steps,\n",
    "    nondeterministic=True,\n",
    "    reward_threshold=1.0,\n",
    "    kwargs={\"num_arms\": 10, \"stationary\": True},\n",
    ")\n",
    "\n",
    "env = gym.make(\"ArmedBanditTestbed-v0\")\n",
    "print(f\"Our env inside its wrappers looks like: {env}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    '''\n",
    "    Base class for agents in a multi-armed bandit environment\n",
    "\n",
    "    (you do not need to add any implementation here)\n",
    "    '''\n",
    "    rng: np.random.Generator\n",
    "\n",
    "    def __init__(self, num_arms: int, seed: int):\n",
    "        self.num_arms = num_arms\n",
    "        self.reset(seed)\n",
    "\n",
    "    def get_action(self) -> ActType:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def observe(self, action: ActType, reward: float, info: dict) -> None:\n",
    "        pass\n",
    "\n",
    "    def reset(self, seed: int) -> None:\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "\n",
    "\n",
    "def run_episode(env: gym.Env, agent: Agent, seed: int):\n",
    "    '''\n",
    "    Runs a single episode of interaction between an agent and an environment.\n",
    "\n",
    "    Args:\n",
    "        env (gym.Env): The environment in which the agent operates.\n",
    "        agent (Agent): The agent that takes actions in the environment.\n",
    "        seed (int): The seed for random number generation to ensure reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.ndarray]: A tuple containing arrays of rewards\n",
    "        received in each step and a flag indicating if the chosen arm was the best.\n",
    "    '''\n",
    "    (rewards, was_best) = ([], [])\n",
    "\n",
    "    env.reset(seed=seed)\n",
    "    agent.reset(seed=seed)\n",
    "\n",
    "    done = False\n",
    "    while not done:\n",
    "        arm = agent.get_action()\n",
    "        (obs, reward, done, info) = env.step(arm)\n",
    "        agent.observe(arm, reward, info)\n",
    "        rewards.append(reward)\n",
    "        was_best.append(1 if arm == info[\"best_arm\"] else 0)\n",
    "\n",
    "    rewards = np.array(rewards, dtype=float)\n",
    "    was_best = np.array(was_best, dtype=int)\n",
    "    return (rewards, was_best)\n",
    "\n",
    "\n",
    "def run_agent(env: gym.Env, agent: Agent, n_runs=200, base_seed=1):\n",
    "    all_rewards = []\n",
    "    all_was_bests = []\n",
    "    base_rng = np.random.default_rng(base_seed)\n",
    "    for n in tqdm(range(n_runs)):\n",
    "        seed = base_rng.integers(low=0, high=10_000, size=1).item()\n",
    "        (rewards, corrects) = run_episode(env, agent, seed)\n",
    "        all_rewards.append(rewards)\n",
    "        all_was_bests.append(corrects)\n",
    "    return (np.array(all_rewards), np.array(all_was_bests))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - implement RandomAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difficulty: ðŸ”´ðŸ”´âšªâšªâšª\n",
    "Importance: ðŸ”µðŸ”µâšªâšªâšª\n",
    "\n",
    "You should spend up to 10-20 minutes on this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:00<00:00, 217.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected correct freq: 0.1, actual: 0.099565\n",
      "Expected average reward: 0.0, actual: 0.006279\n",
      "All tests passed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class RandomAgent(Agent):\n",
    "\n",
    "    def get_action(self) -> ActType:\n",
    "        return self.rng.integers(low=0, high=self.num_arms)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"RandomAgent\"\n",
    "\n",
    "\n",
    "num_arms = 10\n",
    "stationary = True\n",
    "env = gym.make(\"ArmedBanditTestbed-v0\", num_arms=num_arms, stationary=stationary)\n",
    "agent = RandomAgent(num_arms, 0)\n",
    "all_rewards, all_corrects = run_agent(env, agent)\n",
    "\n",
    "print(f\"Expected correct freq: {1/10}, actual: {all_corrects.mean():.6f}\")\n",
    "assert np.isclose(all_corrects.mean(), 1/10, atol=0.05), \"Random agent is not random enough!\"\n",
    "\n",
    "print(f\"Expected average reward: 0.0, actual: {all_rewards.mean():.6f}\")\n",
    "assert np.isclose(all_rewards.mean(), 0, atol=0.05), \"Random agent should be getting mean arm reward, which is zero.\"\n",
    "\n",
    "print(\"All tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - implement reward averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difficulty: ðŸ”´ðŸ”´ðŸ”´âšªâšª\n",
    "Importance: ðŸ”µðŸ”µâšªâšªâšª\n",
    "\n",
    "You should spend up to 20-30 minutes on this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RewardAveraging(Agent):\n",
    "    def __init__(self, num_arms: int, seed: int, epsilon: float, optimism: float):\n",
    "        self.epsilon = epsilon\n",
    "        self.optimism = optimism\n",
    "        super().__init__(num_arms, seed)\n",
    "\n",
    "    def get_action(self):\n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "\n",
    "    def observe(self, action, reward, info):\n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "\n",
    "    def reset(self, seed: int):\n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "\n",
    "    def __repr__(self):\n",
    "        # For the legend, when plotting\n",
    "        return f\"RewardAveraging(eps={self.epsilon}, optimism={self.optimism})\"\n",
    "\n",
    "\n",
    "num_arms = 10\n",
    "stationary = True\n",
    "names = []\n",
    "all_rewards = []\n",
    "env = gym.make(\"ArmedBanditTestbed-v0\", num_arms=num_arms, stationary=stationary)\n",
    "\n",
    "for optimism in [0, 5]:\n",
    "    agent = RewardAveraging(num_arms, 0, epsilon=0.01, optimism=optimism)\n",
    "    (rewards, num_correct) = run_agent(env, agent, n_runs=N_RUNS, base_seed=1)\n",
    "    all_rewards.append(rewards)\n",
    "    names.append(str(agent))\n",
    "    print(agent)\n",
    "    print(f\" -> Frequency of correct arm: {num_correct.mean():.4f}\")\n",
    "    print(f\" -> Average reward: {rewards.mean():.4f}\")\n",
    "\n",
    "utils.plot_rewards(all_rewards, names, moving_avg_window=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabular RL & Policy Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    def __init__(self, num_states: int, num_actions: int, start=0, terminal=None):\n",
    "        self.num_states = num_states\n",
    "        self.num_actions = num_actions\n",
    "        self.start = start\n",
    "        self.terminal = np.array([], dtype=int) if terminal is None else terminal\n",
    "        (self.T, self.R) = self.build()\n",
    "\n",
    "    def build(self):\n",
    "        '''\n",
    "        Constructs the T and R tensors from the dynamics of the environment.\n",
    "\n",
    "        Returns:\n",
    "            T : (num_states, num_actions, num_states) State transition probabilities\n",
    "            R : (num_states, num_actions, num_states) Reward function\n",
    "        '''\n",
    "        num_states = self.num_states\n",
    "        num_actions = self.num_actions\n",
    "        T = np.zeros((num_states, num_actions, num_states))\n",
    "        R = np.zeros((num_states, num_actions, num_states))\n",
    "        for s in range(num_states):\n",
    "            for a in range(num_actions):\n",
    "                (states, rewards, probs) = self.dynamics(s, a)\n",
    "                (all_s, all_r, all_p) = self.out_pad(states, rewards, probs)\n",
    "                T[s, a, all_s] = all_p\n",
    "                R[s, a, all_s] = all_r\n",
    "        return (T, R)\n",
    "\n",
    "    def dynamics(self, state: int, action: int) -> Tuple[Arr, Arr, Arr]:\n",
    "        '''\n",
    "        Computes the distribution over possible outcomes for a given state\n",
    "        and action.\n",
    "\n",
    "        Args:\n",
    "            state  : int (index of state)\n",
    "            action : int (index of action)\n",
    "\n",
    "        Returns:\n",
    "            states  : (m,) all the possible next states\n",
    "            rewards : (m,) rewards for each next state transition\n",
    "            probs   : (m,) likelihood of each state-reward pair\n",
    "        '''\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def render(pi: Arr):\n",
    "        '''\n",
    "        Takes a policy pi, and draws an image of the behavior of that policy, if applicable.\n",
    "\n",
    "        Args:\n",
    "            pi : (num_actions,) a policy\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        '''\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def out_pad(self, states: Arr, rewards: Arr, probs: Arr):\n",
    "        '''\n",
    "        Args:\n",
    "            states  : (m,) all the possible next states\n",
    "            rewards : (m,) rewards for each next state transition\n",
    "            probs   : (m,) likelihood of each state-reward pair\n",
    "\n",
    "        Returns:\n",
    "            states  : (num_states,) all the next states\n",
    "            rewards : (num_states,) rewards for each next state transition\n",
    "            probs   : (num_states,) likelihood of each state-reward pair (including zero-prob outcomes.)\n",
    "        '''\n",
    "        out_s = np.arange(self.num_states)\n",
    "        out_r = np.zeros(self.num_states)\n",
    "        out_p = np.zeros(self.num_states)\n",
    "        for i in range(len(states)):\n",
    "            idx = states[i]\n",
    "            out_r[idx] += rewards[i]\n",
    "            out_p[idx] += probs[i]\n",
    "        return (out_s, out_r, out_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Toy(Environment):\n",
    "    def dynamics(self, state: int, action: int):\n",
    "        '''\n",
    "        Sets up dynamics for the toy environment:\n",
    "            - In state s_L, we move right & get +0 reward regardless of action\n",
    "            - In state s_R, we move left & get +2 reward regardless of action\n",
    "            - In state s_0, we can move left & get +1, or right & get +0\n",
    "        '''\n",
    "        (SL, S0, SR) = (0, 1, 2)\n",
    "        LEFT = 0\n",
    "        num_states = 3\n",
    "        num_actions = 2\n",
    "        assert 0 <= state < self.num_states and 0 <= action < self.num_actions\n",
    "        if state == S0:\n",
    "            if action == LEFT:\n",
    "                (next_state, reward) = (SL, 1)\n",
    "            else:\n",
    "                (next_state, reward) = (SR, 0)\n",
    "        elif state == SL:\n",
    "            (next_state, reward) = (S0, 0)\n",
    "        elif state == SR:\n",
    "            (next_state, reward) = (S0, 2)\n",
    "        return (np.array([next_state]), np.array([reward]), np.array([1]))\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(num_states=3, num_actions=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "Next state (s_next): %{x}<br>Action at current state (a): %{y}<br>Transition<br>Probability: %{z}<extra></extra>",
         "name": "0",
         "texttemplate": "%{z:.2f}",
         "type": "heatmap",
         "x": [
          "s_L",
          "S_0",
          "S_R"
         ],
         "xaxis": "x",
         "y": [
          "a_L",
          "a_R"
         ],
         "yaxis": "y",
         "z": [
          [
           0,
           1,
           0
          ],
          [
           0,
           1,
           0
          ]
         ]
        },
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "Next state (s_next): %{x}<br>Action at current state (a): %{y}<br>Transition<br>Probability: %{z}<extra></extra>",
         "name": "1",
         "texttemplate": "%{z:.2f}",
         "type": "heatmap",
         "x": [
          "s_L",
          "S_0",
          "S_R"
         ],
         "xaxis": "x2",
         "y": [
          "a_L",
          "a_R"
         ],
         "yaxis": "y2",
         "z": [
          [
           1,
           0,
           0
          ],
          [
           0,
           0,
           1
          ]
         ]
        },
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "Next state (s_next): %{x}<br>Action at current state (a): %{y}<br>Transition<br>Probability: %{z}<extra></extra>",
         "name": "2",
         "texttemplate": "%{z:.2f}",
         "type": "heatmap",
         "x": [
          "s_L",
          "S_0",
          "S_R"
         ],
         "xaxis": "x3",
         "y": [
          "a_L",
          "a_R"
         ],
         "yaxis": "y3",
         "z": [
          [
           0,
           1,
           0
          ],
          [
           0,
           1,
           0
          ]
         ]
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {},
          "showarrow": false,
          "text": "Current state is s = s_L",
          "x": 0.15999999999999998,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {},
          "showarrow": false,
          "text": "Current state is s = S_0",
          "x": 0.49999999999999994,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {},
          "showarrow": false,
          "text": "Current state is s = S_R",
          "x": 0.8399999999999999,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "coloraxis": {
         "cmid": 0,
         "colorbar": {
          "title": {
           "text": "Transition<br>Probability"
          }
         },
         "colorscale": [
          [
           0,
           "rgb(103,0,31)"
          ],
          [
           0.1,
           "rgb(178,24,43)"
          ],
          [
           0.2,
           "rgb(214,96,77)"
          ],
          [
           0.3,
           "rgb(244,165,130)"
          ],
          [
           0.4,
           "rgb(253,219,199)"
          ],
          [
           0.5,
           "rgb(247,247,247)"
          ],
          [
           0.6,
           "rgb(209,229,240)"
          ],
          [
           0.7,
           "rgb(146,197,222)"
          ],
          [
           0.8,
           "rgb(67,147,195)"
          ],
          [
           0.9,
           "rgb(33,102,172)"
          ],
          [
           1,
           "rgb(5,48,97)"
          ]
         ]
        },
        "height": 450,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Transition probabilities T(s_next | s, a) for toy environment"
        },
        "width": 1200,
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          0.31999999999999995
         ],
         "linecolor": "black",
         "linewidth": 1,
         "mirror": true,
         "scaleanchor": "y",
         "showline": true,
         "title": {
          "text": "Next state (s_next)"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.33999999999999997,
          0.6599999999999999
         ],
         "linecolor": "black",
         "linewidth": 1,
         "matches": "x",
         "mirror": true,
         "showline": true,
         "title": {
          "text": "Next state (s_next)"
         }
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0.6799999999999999,
          0.9999999999999999
         ],
         "linecolor": "black",
         "linewidth": 1,
         "matches": "x",
         "mirror": true,
         "showline": true,
         "title": {
          "text": "Next state (s_next)"
         }
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "linecolor": "black",
         "linewidth": 1,
         "mirror": true,
         "showline": true,
         "title": {
          "text": "Action at current state (a)"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          1
         ],
         "linecolor": "black",
         "linewidth": 1,
         "matches": "y",
         "mirror": true,
         "showline": true,
         "showticklabels": false
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0,
          1
         ],
         "linecolor": "black",
         "linewidth": 1,
         "matches": "y",
         "mirror": true,
         "showline": true,
         "showticklabels": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "Next state (s_next): %{x}<br>Action at current state (a): %{y}<br>Reward: %{z}<extra></extra>",
         "name": "0",
         "texttemplate": "%{z:.2f}",
         "type": "heatmap",
         "x": [
          "s_L",
          "S_0",
          "S_R"
         ],
         "xaxis": "x",
         "y": [
          "a_L",
          "a_R"
         ],
         "yaxis": "y",
         "z": [
          [
           0,
           0,
           0
          ],
          [
           0,
           0,
           0
          ]
         ]
        },
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "Next state (s_next): %{x}<br>Action at current state (a): %{y}<br>Reward: %{z}<extra></extra>",
         "name": "1",
         "texttemplate": "%{z:.2f}",
         "type": "heatmap",
         "x": [
          "s_L",
          "S_0",
          "S_R"
         ],
         "xaxis": "x2",
         "y": [
          "a_L",
          "a_R"
         ],
         "yaxis": "y2",
         "z": [
          [
           1,
           0,
           0
          ],
          [
           0,
           0,
           0
          ]
         ]
        },
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "Next state (s_next): %{x}<br>Action at current state (a): %{y}<br>Reward: %{z}<extra></extra>",
         "name": "2",
         "texttemplate": "%{z:.2f}",
         "type": "heatmap",
         "x": [
          "s_L",
          "S_0",
          "S_R"
         ],
         "xaxis": "x3",
         "y": [
          "a_L",
          "a_R"
         ],
         "yaxis": "y3",
         "z": [
          [
           0,
           2,
           0
          ],
          [
           0,
           2,
           0
          ]
         ]
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {},
          "showarrow": false,
          "text": "Current state is s = s_L",
          "x": 0.15999999999999998,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {},
          "showarrow": false,
          "text": "Current state is s = S_0",
          "x": 0.49999999999999994,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {},
          "showarrow": false,
          "text": "Current state is s = S_R",
          "x": 0.8399999999999999,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "coloraxis": {
         "cmid": 0,
         "colorbar": {
          "title": {
           "text": "Reward"
          }
         },
         "colorscale": [
          [
           0,
           "rgb(103,0,31)"
          ],
          [
           0.1,
           "rgb(178,24,43)"
          ],
          [
           0.2,
           "rgb(214,96,77)"
          ],
          [
           0.3,
           "rgb(244,165,130)"
          ],
          [
           0.4,
           "rgb(253,219,199)"
          ],
          [
           0.5,
           "rgb(247,247,247)"
          ],
          [
           0.6,
           "rgb(209,229,240)"
          ],
          [
           0.7,
           "rgb(146,197,222)"
          ],
          [
           0.8,
           "rgb(67,147,195)"
          ],
          [
           0.9,
           "rgb(33,102,172)"
          ],
          [
           1,
           "rgb(5,48,97)"
          ]
         ]
        },
        "height": 450,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Rewards R(s, a, s_next) for toy environment"
        },
        "width": 1200,
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          0.31999999999999995
         ],
         "linecolor": "black",
         "linewidth": 1,
         "mirror": true,
         "scaleanchor": "y",
         "showline": true,
         "title": {
          "text": "Next state (s_next)"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.33999999999999997,
          0.6599999999999999
         ],
         "linecolor": "black",
         "linewidth": 1,
         "matches": "x",
         "mirror": true,
         "showline": true,
         "title": {
          "text": "Next state (s_next)"
         }
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0.6799999999999999,
          0.9999999999999999
         ],
         "linecolor": "black",
         "linewidth": 1,
         "matches": "x",
         "mirror": true,
         "showline": true,
         "title": {
          "text": "Next state (s_next)"
         }
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "linecolor": "black",
         "linewidth": 1,
         "mirror": true,
         "showline": true,
         "title": {
          "text": "Action at current state (a)"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          1
         ],
         "linecolor": "black",
         "linewidth": 1,
         "matches": "y",
         "mirror": true,
         "showline": true,
         "showticklabels": false
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0,
          1
         ],
         "linecolor": "black",
         "linewidth": 1,
         "matches": "y",
         "mirror": true,
         "showline": true,
         "showticklabels": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "toy = Toy()\n",
    "\n",
    "actions = [\"a_L\", \"a_R\"]\n",
    "states = [\"s_L\", \"S_0\", \"S_R\"]\n",
    "\n",
    "imshow(\n",
    "    toy.T, # dimensions (s, a, s_next)\n",
    "    title=\"Transition probabilities T(s_next | s, a) for toy environment\",\n",
    "    facet_col=0, facet_labels=[f\"Current state is s = {s}\" for s in states], y=actions, x=states,\n",
    "    labels = {\"x\": \"Next state (s_next)\", \"y\": \"Action at current state (a)\", \"color\": \"Transition<br>Probability\"},\n",
    "    text_auto = \".2f\", border=True, width=1200, height=450,\n",
    ")\n",
    "\n",
    "imshow(\n",
    "    toy.R, # dimensions (s, a, s_next)\n",
    "    title=\"Rewards R(s, a, s_next) for toy environment\",\n",
    "    facet_col=0, facet_labels=[f\"Current state is s = {s}\" for s in states], y=actions, x=states,\n",
    "    labels = {\"x\": \"Next state (s_next)\", \"y\": \"Action at current state (a)\", \"color\": \"Reward\"},\n",
    "    text_auto = \".2f\", border=True, width=1200, height=450,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âž¡ï¸â¬‡ï¸âž¡ï¸ðŸŸ©\n",
      "â¬†ï¸â¬›âž¡ï¸ðŸŸ¥\n",
      "â¬…ï¸â¬†ï¸â¬…ï¸â¬†ï¸\n"
     ]
    }
   ],
   "source": [
    "class Norvig(Environment):\n",
    "    def dynamics(self, state: int, action: int) -> Tuple[Arr, Arr, Arr]:\n",
    "        def state_index(state):\n",
    "            assert 0 <= state[0] < self.width and 0 <= state[1] < self.height, print(state)\n",
    "            pos = state[0] + state[1] * self.width\n",
    "            assert 0 <= pos < self.num_states, print(state, pos)\n",
    "            return pos\n",
    "\n",
    "        pos = self.states[state]\n",
    "        move = self.actions[action]\n",
    "        if state in self.terminal or state in self.walls:\n",
    "            return (np.array([state]), np.array([0]), np.array([1]))\n",
    "        out_probs = np.zeros(self.num_actions) + 0.1\n",
    "        out_probs[action] = 0.7\n",
    "        out_states = np.zeros(self.num_actions, dtype=int) + self.num_actions\n",
    "        out_rewards = np.zeros(self.num_actions) + self.penalty\n",
    "        new_states = [pos + x for x in self.actions]\n",
    "        for (i, s_new) in enumerate(new_states):\n",
    "            if not (0 <= s_new[0] < self.width and 0 <= s_new[1] < self.height):\n",
    "                out_states[i] = state\n",
    "                continue\n",
    "            new_state = state_index(s_new)\n",
    "            if new_state in self.walls:\n",
    "                out_states[i] = state\n",
    "            else:\n",
    "                out_states[i] = new_state\n",
    "            for idx in range(len(self.terminal)):\n",
    "                if new_state == self.terminal[idx]:\n",
    "                    out_rewards[i] = self.goal_rewards[idx]\n",
    "        return (out_states, out_rewards, out_probs)\n",
    "\n",
    "    def render(self, pi: Arr):\n",
    "        assert len(pi) == self.num_states\n",
    "        emoji = [\"â¬†ï¸\", \"âž¡ï¸\", \"â¬‡ï¸\", \"â¬…ï¸\"]\n",
    "        grid = [emoji[act] for act in pi]\n",
    "        grid[3] = \"ðŸŸ©\"\n",
    "        grid[7] = \"ðŸŸ¥\"\n",
    "        grid[5] = \"â¬›\"\n",
    "        print(\"\".join(grid[0:4]) + \"\\n\" + \"\".join(grid[4:8]) + \"\\n\" + \"\".join(grid[8:]))\n",
    "\n",
    "    def __init__(self, penalty=-0.04):\n",
    "        self.height = 3\n",
    "        self.width = 4\n",
    "        self.penalty = penalty\n",
    "        num_states = self.height * self.width\n",
    "        num_actions = 4\n",
    "        self.states = np.array([[x, y] for y in range(self.height) for x in range(self.width)])\n",
    "        self.actions = np.array([[0, -1], [1, 0], [0, 1], [-1, 0]])\n",
    "        self.dim = (self.height, self.width)\n",
    "        terminal = np.array([3, 7], dtype=int)\n",
    "        self.walls = np.array([5], dtype=int)\n",
    "        self.goal_rewards = np.array([1.0, -1])\n",
    "        super().__init__(num_states, num_actions, start=8, terminal=terminal)\n",
    "\n",
    "\n",
    "# Example use of `render`: print out a random policy\n",
    "norvig = Norvig()\n",
    "pi_random = np.random.randint(0, 4, (12,))\n",
    "norvig.render(pi_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged in 141 steps.\n",
      "Converged in 116 steps.\n",
      "Converged in 123 steps.\n",
      "Converged in 148 steps.\n",
      "Converged in 100 steps.\n",
      "All tests in `test_policy_eval` passed!\n"
     ]
    }
   ],
   "source": [
    "def policy_eval_numerical(env: Environment, pi: Arr, gamma=0.99, eps=1e-8, max_iterations=10_000) -> Arr:\n",
    "    '''\n",
    "    Numerically evaluates the value of a given policy by iterating the Bellman equation\n",
    "    Args:\n",
    "        env: Environment\n",
    "        pi : shape (num_states,) - The policy to evaluate\n",
    "        gamma: float - Discount factor\n",
    "        eps  : float - Tolerance\n",
    "        max_iterations: int - Maximum number of iterations to run\n",
    "    Outputs:\n",
    "        value : float (num_states,) - The value function for policy pi\n",
    "    '''\n",
    "    # initialize V(s) = zeros(num_states)\n",
    "    # for i in max_iterations:\n",
    "    #   update V_current = sum(T[s,a,s'] * (R[s,a,s'] + gamma * V(s)))\n",
    "    #   check if Vcurrent - Vold < eps:\n",
    "    #       mebbe break\n",
    "    #   update vold\n",
    "    v_old = np.zeros(env.num_states)\n",
    "    for _ in range(max_iterations):\n",
    "        # print(env.R.shape)\n",
    "        # v_current = np.sum((env.T[v_old, pi, :] * (env.R[v_old, pi, :] + gamma * v_old)), axis=-1)\n",
    "        gV = gamma * v_old\n",
    "        R = env.R[np.arange(env.num_states), pi, :] \n",
    "        T = env.T[np.arange(env.num_states), pi, :] \n",
    "        v_current = np.sum(T * (R + gV), axis = -1)\n",
    "\n",
    "        \n",
    "        if np.max(np.abs(v_current - v_old)) < eps:\n",
    "            break\n",
    "        v_old = v_current\n",
    "    return v_current\n",
    "  \n",
    "\n",
    "tests.test_policy_eval(policy_eval_numerical, exact=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arena",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
